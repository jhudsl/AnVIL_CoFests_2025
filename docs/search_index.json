[["index.html", "AnVIL CoFests! 2025 What are CoFests!? What’s in a name: CollaborationFests! and Hackathons Previous AnVIL CoFests! AnVIL Collection", " AnVIL CoFests! 2025 September 01, 2025 What are CoFests!? CollaborationFests!, also known as CoFests! (and sometimes as “hackathons”), are collaborative work events where we expand and improve the AnVIL community and the AnVIL ecosystem. Sometimes these gatherings are focused on AnVIL, and sometimes they are part of larger communities. Modified from https://galaxyproject.org/events/cofests What’s in a name: CollaborationFests! and Hackathons We collaborate. AnVIL collaborative events are emphatically called CollaborationFests! rather than Hackathons. Putting Collaboration in the name emphasizes what the events are about for us, and Fest communicates that they are fun events (which they are). “Hackathon” implies an emphasis on code. CoFests! are about contributing and learning how to contribute to all aspects of AnVIL, including training material, community infrastructure, documentation, unit tests, bug reports, and yes, even code. First and foremost AnVIL CoFests! are about growing the community of future contributors. Idea inspiration from [GCC2024][GCC2018] Reporting inspiration from [BioC2018][BioC2020][BioC2023] Previous AnVIL CoFests! ACC 2024 at Cold Spring Harbor Laboratories AnVIL Collection Please check out our full collection of AnVIL and related resources: https://hutchdatascience.org/AnVIL_Collection/ "],["organizer-guide.html", "Organizer Guide CoFests! Goals Logistics Final Product / Report Out", " Organizer Guide The second AnVIL Community Conference (ACC) 2025 will take place on September 4-5, 2025 in Nashville, TN. Overall, ACC 2025 is a key event for professionals in the genomics community interested in biomedical and genomic cloud computing and features keynotes, town halls, CoFests! and other such component events. CoFests! provide attendees the opportunity to get some hands-on experience with AnVIL and foster connections within the AnVIL community. CoFests! Goals Build an inclusive community that is supportive of newcomers Collaborate and contribute to open science Produce a final product that accomplishes one of the following for a topic Makes useful forward progress Identifies opportunities and boundaries or limitations Logistics 3 Parallel tracks, 2.5 hrs each Sept 4 AnVIL 101 Polygenic Risk Score Analysis (title TBD) Reproducible Analysis on AnVIL (title TBD) Scientific Lead and AnVIL Outreach coordinator for support We expect 4-10 participants per track Note that a virtual option for AnVIL 101 will be offered on Sept 2 prior to ACC 2025. Prior to the CoFests, the scientific lead and AnVIL Outreach coordinators will work together to enumerate some ideas for final products and post them publicly in this book. The AnVIL Outreach coordinator will help add content to this guide, onboard newer AnVIL users to the platform, and provide guidance on the final product / report out. Final Product / Report Out The final product of CoFests doesn’t need to be code! These Collaboration Fests can support story-boarding future work or development of documentation or training materials. If it’s something that will help the community and make progress on an AnVIL associated topic and there’s sufficient interest, the idea is game! As Galaxy phrased it for their CoFests: [The goal of collaboration fests is to expand the ecosystem] Not just the code, but the whole ecosystem. That includes training, tools, best practice workflows, documentation, test cases, translations, infrastructure, and yes, even code. It helps us a lot if you can fill out some basic Report Out details. At the end of the session, your track will share a final report during the CoFest Recap Session! Task Time &amp; Lead Problem statement. Provide background info on the track’s overall topic and may include a brief summary of the pre-worked collaboration ideas. 15-20 minutes (Scientific Lead) Brainstorming. What project will the track tackle? Focus on understanding the participant backgrounds and skills and matching those with track ideas and actionable tasks to accomplish the goal. 5-10 minutes (Both) Onboarding. Handle billing accounts and other logistics necessary to accomplish the work. 5-10 minutes (AnVIL Outreach coordinator) Work Formal collaboration work time). 1.25-1.75 hours (N/A) Construct a “report out”. The report out may be a Google doc, Google slides, a GitHub repository, a website, an OTTR book, etc. 15-30 minutes (AnVIL Outreach coordinator) "],["anvil-101.html", "Chapter 1 AnVIL 101 1.1 About 1.2 Workspace 1.3 Data on AnVIL", " Chapter 1 AnVIL 101 Led by: Ava Hoffman, Fred Hutch Cancer Center 1.1 About This track will consist of both an overview and a hands-on workshop to provide individuals with a starting point to their work on AnVIL. Participants are not required to supply their own data, as publicly available data and an AnVIL workspace will be provided as part of the CoFest track. 1.2 Workspace The workspace for this track can be found at: https://anvil.terra.bio/#workspaces/anvil-outreach/AnVIL101-CoFest2025 1.3 Data on AnVIL Gathering your data is one of the first steps of any analysis (assuming you already have your research question in mind!). Working on AnVIL, you might be using data from a few different places: Data already on AnVIL (or GCP) Data from a public repository (such as SRA) Data from a protected source (such as dbGaP) Data from your own source (such as your laptop or an institutional HPC) 1.3.1 Data already on AnVIL (or GCP) Luckily, if data is already on AnVIL, there is less you have to do to start working with it. Under the hood, AnVIL uses Google Cloud Platform (GCP) to store data. Each data file will therefore get a Google Cloud URI that starts with gs://. Within the context of Google Cloud Storage, the GCP URI is a Uniform Resource Identifier that points to a specific resource, such as a bucket or an object (file), within Cloud Storage. Some consortia have created AnVIL Workspaces to organize their data. If you clone (copy) these workspaces, links to the data will be copied as well. You can then point to these links in WDL workflows, or copy these data into interactive compute environments (like Galaxy, RStudio, or Jupyter Notebooks/Terminal environment). If your data is already stored in GCP, you can use the links directly. 1.3.2 Data from a public repository If our data is located elsewhere, such as in SRA, we will need to bring the data into AnVIL/GCP storage. We could manually upload and download data, but that could take a long time, and might get interrupted if our computer or internet connection acts up. Better that we cut out the middle step, and have the SRA talk directly to AnVIL! In the next steps, we’ll copy over some SRA data (in FASTQ format) to AnVIL. Our goal is to get some RNA-Seq data associated with this study. Clone the Workspace. Use the billing project provided by your instructor, or one of your choice. You might want to call the workspace “AnVIL101-CoFest2025-{your name here}”, because workspace names on the same billing project must be unique. Go to the “WORKFLOWS” tab. We’ll use a WDL workflow to make sure the SRA data is in GCP and accessible in AnVIL. Click “Find a Workflow”. Click on “Dockstore.org”. Once on Dockstore, browse for “SRA fetch”. Scroll down a bit to find “aofarrel/SRANWRP/pull_FASTQs_from_SRA_by_run”. Click on this workflow, or go directly to it here. On the righthand side, find “Launch with” and select “AnVIL”. On the dropdown for “Destination Workspace” select the workspace clone you made above (“AnVIL101-CoFest2025-{your name here}”). Back on AnVIL, select the workflow you just imported (“pull_FASTQs_from_SRA_by_run”). In the box under “Input value” for the “sra_accessions” variable, enter an SRA accession listed at the site here: https://www.ncbi.nlm.nih.gov/Traces/study/?acc=SRP131764&amp;o=acc_s%3Aa. It should start with “SRR”. Don’t forget quotation marks (e.g., “SRR6652526”). Click the “Save” button. Then, click “Launch”. Click “Launch” again to confirm. It will take 5-6 minutes. While your workflow is running, launch a Jupyter notebook. Go to “ANALYSES” tab, click “Start” and name your notebook. Default parameters and Python can be used. You can check the status under the “SUBMISSION HISTORY” tab. Click on the “Submission ID” to see the output on GCP. Locate your files by clicking through the folders. On the three-dot menu, you can copy the gsutil URI. We can use this link to bring our data into an AnVIL compute environment. Navigate back to the Jupyter Notebook. Click the “Terminal” icon on the righthand side. Check out the files you have in this compute environment with ls. You can also see the GCP info, including the workspace bucket with gcloud storage ls. Remember that GCP storage (data “in the workspace”) differs from the temporary storage associated with a Jupyter computing environment. You’ll need to move data back and forth. Bring data into this computing environment: gcloud storage cp {URI HERE} .. Type ls again to confirm the file is now available for you to work with. "],["polygenic-risk-score-prs-mix-analysis-in-anvil.html", "Chapter 2 Polygenic Risk Score (PRS) Mix Analysis in AnVIL 2.1 About", " Chapter 2 Polygenic Risk Score (PRS) Mix Analysis in AnVIL Led by: Matthew Lebo, PhD and Shruti Parpattedar 2.1 About This track, run by the AnVIL Clinical Resource team, will consist of both an overview and a hands-on workshop to provide individuals with an understanding of polygenic scores and how to run and evaluate them in AnVIL. First, we will level-set by providing an overview of the current state of polygenic analysis, with a focus on polygenic risk scores (PRS) and PRS Mix scores. Next, we will jointly work with participants to run PRS analyses in AnVIL using the WDL framework. These tasks will cover various components of the PRS mix workflow, with the goal of enabling users to import, set up and run the WDL on their own. We will also engage with participants to get feedback and create user-friendly documents to enable processing of this workflow once published to the broader community. Participants are not required to supply their own data, as publicly available data and an AnVIL workspace will be provided as part of the CoFest track. Users who are interested in running the analyses on their own data are welcome, but should have their own workspace in which to run the analyses. "],["reproducible-analysis-on-anvil-title-tbd.html", "Chapter 3 Reproducible Analysis on AnVIL (title TBD) 3.1 About 3.2 Workspace", " Chapter 3 Reproducible Analysis on AnVIL (title TBD) Led by: Allissa Dillman, Engagement and Outreach Lead for the Office of Data Science Strategy at the NIH AnVIL Outreach coordinator: Kate Isaac 3.1 About This track will consist of Participants are not required to supply their own data, as publicly available data and an AnVIL workspace will be provided as part of the CoFest track. 3.2 Workspace The workspace for this track can be found at "],["about-the-authors.html", "About the Authors", " About the Authors These credits are based on our course contributors table guidelines.     Credits Names Pedagogy Lead Content Instructor(s) FirstName LastName Lecturer(s) (include chapter name/link in parentheses if only for specific chapters) - make new line if more than one chapter involved Delivered the course in some way - video or audio Content Author(s) (include chapter name/link in parentheses if only for specific chapters) - make new line if more than one chapter involved If any other authors besides lead instructor Content Contributor(s) (include section name/link in parentheses) - make new line if more than one section involved Wrote less than a chapter Content Editor(s)/Reviewer(s) Checked your content Content Director(s) Helped guide the content direction Content Consultants (include chapter name/link in parentheses or word “General”) - make new line if more than one chapter involved Gave high level advice on content Acknowledgments Gave small assistance to content but not to the level of consulting Production Content Publisher(s) Helped with publishing platform Content Publishing Reviewer(s) Reviewed overall content and aesthetics on publishing platform Technical Course Publishing Engineer(s) Helped with the code for the technical aspects related to the specific course generation Template Publishing Engineers Candace Savonen, Carrie Wright, Ava Hoffman Publishing Maintenance Engineer Candace Savonen Technical Publishing Stylists Carrie Wright, Ava Hoffman, Candace Savonen, Katherine Cox Package Developers (ottrpal) Candace Savonen, Ava Hoffman, Howard Baek, Kate Isaac, Carrie Wright, John Muschelli Art and Design Illustrator(s) Created graphics for the course Figure Artist(s) Created figures/plots for course Videographer(s) Filmed videos Videography Editor(s) Edited film Audiographer(s) Recorded audio Audiography Editor(s) Edited audio recordings Funding Funder(s) Institution/individual who funded course including grant number Funding Staff Staff members who help with funding   ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 4.3.2 (2023-10-31) ## os Ubuntu 22.04.4 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Etc/UTC ## date 2025-09-01 ## pandoc 3.1.1 @ /usr/local/bin/ (via rmarkdown) ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## bookdown 0.43 2025-04-15 [1] CRAN (R 4.3.2) ## bslib 0.6.1 2023-11-28 [1] RSPM (R 4.3.0) ## cachem 1.0.8 2023-05-01 [1] RSPM (R 4.3.0) ## cli 3.6.2 2023-12-11 [1] RSPM (R 4.3.0) ## devtools 2.4.5 2022-10-11 [1] RSPM (R 4.3.0) ## digest 0.6.34 2024-01-11 [1] RSPM (R 4.3.0) ## ellipsis 0.3.2 2021-04-29 [1] RSPM (R 4.3.0) ## evaluate 1.0.4 2025-06-18 [1] CRAN (R 4.3.2) ## fastmap 1.1.1 2023-02-24 [1] RSPM (R 4.3.0) ## fs 1.6.3 2023-07-20 [1] RSPM (R 4.3.0) ## glue 1.7.0 2024-01-09 [1] RSPM (R 4.3.0) ## htmltools 0.5.7 2023-11-03 [1] RSPM (R 4.3.0) ## htmlwidgets 1.6.4 2023-12-06 [1] RSPM (R 4.3.0) ## httpuv 1.6.14 2024-01-26 [1] RSPM (R 4.3.0) ## jquerylib 0.1.4 2021-04-26 [1] RSPM (R 4.3.0) ## jsonlite 1.8.8 2023-12-04 [1] RSPM (R 4.3.0) ## knitr 1.50 2025-03-16 [1] CRAN (R 4.3.2) ## later 1.3.2 2023-12-06 [1] RSPM (R 4.3.0) ## lifecycle 1.0.4 2023-11-07 [1] RSPM (R 4.3.0) ## magrittr 2.0.3 2022-03-30 [1] RSPM (R 4.3.0) ## memoise 2.0.1 2021-11-26 [1] RSPM (R 4.3.0) ## mime 0.12 2021-09-28 [1] RSPM (R 4.3.0) ## miniUI 0.1.1.1 2018-05-18 [1] RSPM (R 4.3.0) ## pkgbuild 1.4.3 2023-12-10 [1] RSPM (R 4.3.0) ## pkgload 1.3.4 2024-01-16 [1] RSPM (R 4.3.0) ## profvis 0.3.8 2023-05-02 [1] RSPM (R 4.3.0) ## promises 1.2.1 2023-08-10 [1] RSPM (R 4.3.0) ## purrr 1.0.2 2023-08-10 [1] RSPM (R 4.3.0) ## R6 2.5.1 2021-08-19 [1] RSPM (R 4.3.0) ## Rcpp 1.0.12 2024-01-09 [1] RSPM (R 4.3.0) ## remotes 2.4.2.1 2023-07-18 [1] RSPM (R 4.3.0) ## rlang 1.1.6 2025-04-11 [1] CRAN (R 4.3.2) ## rmarkdown 2.25 2023-09-18 [1] RSPM (R 4.3.0) ## sass 0.4.8 2023-12-06 [1] RSPM (R 4.3.0) ## sessioninfo 1.2.2 2021-12-06 [1] RSPM (R 4.3.0) ## shiny 1.8.0 2023-11-17 [1] RSPM (R 4.3.0) ## stringi 1.8.3 2023-12-11 [1] RSPM (R 4.3.0) ## stringr 1.5.1 2023-11-14 [1] RSPM (R 4.3.0) ## urlchecker 1.0.1 2021-11-30 [1] RSPM (R 4.3.0) ## usethis 2.2.3 2024-02-19 [1] RSPM (R 4.3.0) ## vctrs 0.6.5 2023-12-01 [1] RSPM (R 4.3.0) ## xfun 0.52 2025-04-02 [1] CRAN (R 4.3.2) ## xtable 1.8-4 2019-04-21 [1] RSPM (R 4.3.0) ## yaml 2.3.10 2024-07-26 [1] CRAN (R 4.3.2) ## ## [1] /usr/local/lib/R/site-library ## [2] /usr/local/lib/R/library ## ## ────────────────────────────────────────────────────────────────────────────── "],["references.html", "Chapter 4 References", " Chapter 4 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
